import os
import aiofiles
import aiohttp
import logging
from typing import Dict, List, Optional, Tuple
from pathlib import Path
from config import DOWNLOAD_DIR, MAX_FILE_SIZE, SUPPORTED_EXTENSIONS
import zipfile
try:
    import rarfile
    RAR_SUPPORT = True
except ImportError:
    RAR_SUPPORT = False

logger = logging.getLogger(__name__)

class DocumentDownloader:
    def __init__(self, download_dir: str = DOWNLOAD_DIR):
        self.download_dir = Path(download_dir)
        self.download_dir.mkdir(exist_ok=True)
    
    async def download_documents(self, tender_data: Dict, reg_number: str) -> Dict:
        """
        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —Å–∫–∞—á–∏–≤–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã —Ç–µ–Ω–¥–µ—Ä–∞
        """
        # –ï—Å–ª–∏ tender_data ‚Äî —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å —Å –æ–¥–Ω–∏–º –∫–ª—é—á–æ–º (–Ω–æ–º–µ—Ä–æ–º —Ç–µ–Ω–¥–µ—Ä–∞), —Ä–∞–±–æ—Ç–∞–µ–º —Å –µ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º—ã–º
        if len(tender_data) == 1 and isinstance(list(tender_data.values())[0], dict):
            tender_data = list(tender_data.values())[0]

        documents = tender_data.get("–î–æ–∫—É–º–µ–Ω—Ç—ã", [])
        all_files = []
        for doc in documents:
            files = doc.get("–§–∞–π–ª—ã", [])
            for f in files:
                all_files.append(f)

        if not all_files:
            logger.info(f"[downloader] üìÑ –î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è —Ç–µ–Ω–¥–µ—Ä–∞ {reg_number}")
            return {"success": 0, "failed": 0, "files": []}

        logger.info(f"[downloader] üì• –ù–∞—á–∏–Ω–∞–µ–º —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ {len(all_files)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

        downloaded_files = []
        success_count = 0
        failed_count = 0
        # –ó–∞–º–µ–Ω—è–µ–º documents –Ω–∞ all_files –≤ —Ü–∏–∫–ª–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=60)) as session:
            for file_info in all_files:
                try:
                    result = await self._download_single_document(session, file_info, reg_number)
                    if result:
                        downloaded_files.append(result)
                        # –ï—Å–ª–∏ —ç—Ç–æ –∞—Ä—Ö–∏–≤, —Ä–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º
                        ext = Path(result['saved_name']).suffix.lower()
                        if ext == '.zip':
                            extracted = self._extract_zip(result['path'])
                            downloaded_files.extend(extracted)
                        elif ext == '.rar' and RAR_SUPPORT:
                            extracted = self._extract_rar(result['path'])
                            downloaded_files.extend(extracted)
                        success_count += 1
                    else:
                        failed_count += 1
                except Exception as e:
                    logger.error(f"[downloader] ‚ùå –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
                    failed_count += 1
        
        logger.info(f"[downloader] ‚úÖ –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {success_count} —É—Å–ø–µ—à–Ω–æ, {failed_count} –Ω–µ —É–¥–∞–ª–æ—Å—å")
        
        return {
            "success": success_count,
            "failed": failed_count,
            "files": downloaded_files
        }
    
    async def _download_single_document(self, session: aiohttp.ClientSession, doc: Dict, reg_number: str) -> Optional[Dict]:
        """
        –°–∫–∞—á–∏–≤–∞–µ—Ç –æ–¥–∏–Ω –¥–æ–∫—É–º–µ–Ω—Ç –ø–æ Url –∏ –ù–∞–∑–≤–∞–Ω–∏—é, –æ–ø—Ä–µ–¥–µ–ª—è—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –ø–æ Content-Type
        """
        import mimetypes
        import os

        url = doc.get("Url")
        name = doc.get("–ù–∞–∑–≤–∞–Ω–∏–µ", "unnamed")

        if not url:
            logger.warning(f"[downloader] ‚ö†Ô∏è –ù–µ—Ç —Å—Å—ã–ª–∫–∏ (Url) –¥–ª—è —Ñ–∞–π–ª–∞ {name}")
            return None

        # –ü–æ–¥–¥–µ–ª–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –±—Ä–∞—É–∑–µ—Ä–∞
        referer = f"https://zakupki.gov.ru/epz/order/notice/ea20/view/common-info.html?regNumber={reg_number}"
        headers = {
            "User-Agent": (
                "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                "AppleWebKit/537.36 (KHTML, like Gecko) "
                "Chrome/125.0.0.0 Safari/537.36"
            ),
            "Accept": "*/*",
            "Accept-Language": "ru,en;q=0.9",
            "Referer": referer
        }

        try:
            async with session.get(url, headers=headers) as response:
                if response.status != 200:
                    logger.warning(f"[downloader] ‚ö†Ô∏è HTTP {response.status} –¥–ª—è {name}")
                    return None

                # 1. –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –∏–º—è —Ñ–∞–π–ª–∞ –∏–∑ Content-Disposition
                import re
                cd = response.headers.get("Content-Disposition")
                filename = None
                if cd:
                    match = re.search(r'filename="?([^";]+)"?', cd)
                    if match:
                        filename = match.group(1)

                # 2. –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ API
                if not filename:
                    filename = name

                # 3. –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
                ext = os.path.splitext(filename)[1]
                if not ext:
                    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å ‚Äî —Å—Ç–∞–≤–∏–º .pdf –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                    ext = ".pdf"
                    filename += ext

                # 4. –°–æ–∑–¥–∞—ë–º –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
                safe_filename = self._create_safe_filename(reg_number, filename)
                file_path = self.download_dir / safe_filename

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
                content_length = response.headers.get('content-length')
                if content_length and int(content_length) > MAX_FILE_SIZE:
                    logger.warning(f"[downloader] ‚ö†Ô∏è –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π: {name} ({content_length} –±–∞–π—Ç)")
                    return None

                # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
                content = await response.read()
                if len(content) > MAX_FILE_SIZE:
                    logger.warning(f"[downloader] ‚ö†Ô∏è –§–∞–π–ª –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏–º–∏—Ç –ø–æ—Å–ª–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: {name}")
                    return None

                async with aiofiles.open(file_path, 'wb') as f:
                    await f.write(content)

                logger.info(f"[downloader] ‚úÖ –°–∫–∞—á–∞–Ω —Ñ–∞–π–ª: {safe_filename}")

                return {
                    "original_name": name,
                    "saved_name": safe_filename,
                    "path": str(file_path),
                    "size": len(content),
                    "url": url
                }
        except aiohttp.ClientError as e:
            logger.error(f"[downloader] üåê –û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ {name}: {e}")
        except Exception as e:
            logger.error(f"[downloader] ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ {name}: {e}")
        return None
    
    def _is_supported_extension(self, filename: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –ª–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞"""
        return any(filename.lower().endswith(ext) for ext in SUPPORTED_EXTENSIONS)
    
    def _create_safe_filename(self, reg_number: str, original_name: str) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞"""
        import re
        from datetime import datetime
        
        # –£–±–∏—Ä–∞–µ–º –Ω–µ–±–µ–∑–æ–ø–∞—Å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
        safe_name = re.sub(r'[^\w\-_.]', '_', original_name)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –º–µ—Ç–∫—É –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        return f"{reg_number}_{timestamp}_{safe_name}"
    
    def _extract_zip(self, file_path: str) -> List[Dict]:
        """–†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ—Ç zip-–∞—Ä—Ö–∏–≤ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤"""
        extracted = []
        try:
            with zipfile.ZipFile(file_path, 'r') as zf:
                for member in zf.namelist():
                    ext = Path(member).suffix.lower()
                    if ext in SUPPORTED_EXTENSIONS:
                        out_path = self.download_dir / Path(member).name
                        zf.extract(member, self.download_dir)
                        extracted.append({
                            "original_name": member,
                            "saved_name": Path(member).name,
                            "path": str(out_path),
                            "size": out_path.stat().st_size,
                            "uid": None
                        })
        except Exception as e:
            logger.error(f"[downloader] ‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏ zip: {e}")
        return extracted
    
    def _extract_rar(self, file_path: str) -> List[Dict]:
        """–†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ—Ç rar-–∞—Ä—Ö–∏–≤ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤"""
        extracted = []
        if not RAR_SUPPORT:
            logger.warning("[downloader] RAR –∞—Ä—Ö–∏–≤—ã –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è (rarfile –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω)")
            return extracted
        try:
            with rarfile.RarFile(file_path) as rf:
                for member in rf.namelist():
                    ext = Path(member).suffix.lower()
                    if ext in SUPPORTED_EXTENSIONS:
                        out_path = self.download_dir / Path(member).name
                        rf.extract(member, self.download_dir)
                        extracted.append({
                            "original_name": member,
                            "saved_name": Path(member).name,
                            "path": str(out_path),
                            "size": out_path.stat().st_size,
                            "uid": None
                        })
        except Exception as e:
            logger.error(f"[downloader] ‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏ rar: {e}")
        return extracted
    
    def get_downloaded_files(self, reg_number: str) -> List[Dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–∫–∞—á–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Ç–µ–Ω–¥–µ—Ä–∞"""
        files = []
        for file_path in self.download_dir.glob(f"{reg_number}_*"):
            if file_path.is_file():
                files.append({
                    "name": file_path.name,
                    "path": str(file_path),
                    "size": file_path.stat().st_size
                })
        return files
    
    def cleanup_old_files(self, max_age_hours: int = 24) -> int:
        """–£–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –º–µ—Å—Ç–∞"""
        import time
        from datetime import datetime, timedelta
        
        cutoff_time = datetime.now() - timedelta(hours=max_age_hours)
        deleted_count = 0
        
        for file_path in self.download_dir.iterdir():
            if file_path.is_file():
                file_time = datetime.fromtimestamp(file_path.stat().st_mtime)
                if file_time < cutoff_time:
                    try:
                        file_path.unlink()
                        deleted_count += 1
                        logger.info(f"[downloader] üóëÔ∏è –£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª: {file_path.name}")
                    except Exception as e:
                        logger.error(f"[downloader] ‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file_path.name}: {e}")
        
        return deleted_count

# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∑–∞–≥—Ä—É–∑—á–∏–∫–∞
downloader = DocumentDownloader()

# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º –∫–æ–¥–æ–º
async def download_documents(tender_data: Dict, reg_number: str) -> Dict:
    """–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º –∫–æ–¥–æ–º"""
    return await downloader.download_documents(tender_data, reg_number)

def download_documents_sync(tender_data: Dict, reg_number: str) -> Dict:
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏"""
    import asyncio
    return asyncio.run(downloader.download_documents(tender_data, reg_number))
