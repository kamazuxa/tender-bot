import logging
import asyncio
from typing import Dict, List, Optional
from pathlib import Path
from openai import OpenAI
from config import OPENAI_API_KEY, OPENAI_MODEL, USE_VPN_FOR_OPENAI, VPN_INTERFACE
import mimetypes
try:
    import pytesseract
    from PIL import Image
    OCR_SUPPORT = True
except ImportError:
    OCR_SUPPORT = False
try:
    import PyPDF2
    PDF_SUPPORT = True
except ImportError:
    PDF_SUPPORT = False

logger = logging.getLogger(__name__)

class DocumentAnalyzer:
    def __init__(self, api_key: str, model: str = OPENAI_MODEL):
        self.api_key = api_key
        self.model = model
        self.client = OpenAI(api_key=api_key)
    
    async def analyze_tender_documents(self, tender_info: Dict, downloaded_files: List[Dict]) -> Dict:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã —Ç–µ–Ω–¥–µ—Ä–∞ —Å –ø–æ–º–æ—â—å—é OpenAI
        """
        if not downloaded_files:
            logger.info("[analyzer] üìÑ –ù–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return self._create_empty_analysis()
        
        logger.info(f"[analyzer] ü§ñ –ù–∞—á–∏–Ω–∞–µ–º –∞–Ω–∞–ª–∏–∑ {len(downloaded_files)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        
        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ —Ç–µ–Ω–¥–µ—Ä–µ
            tender_context = self._prepare_tender_context(tender_info)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
            document_analyses = []
            for file_info in downloaded_files:
                try:
                    analysis = await self._analyze_single_document(file_info, tender_context)
                    if analysis:
                        document_analyses.append(analysis)
                except Exception as e:
                    logger.error(f"[analyzer] ‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {file_info.get('name', 'unknown')}: {e}")
            
            # –°–æ–∑–¥–∞–µ–º –æ–±—â–∏–π –∞–Ω–∞–ª–∏–∑
            overall_analysis = await self._create_overall_analysis(tender_info, document_analyses)
            logger.info(f"[analyzer] ‚úÖ –û–±—â–∏–π –∞–Ω–∞–ª–∏–∑: {overall_analysis}")
            
            return {
                "tender_summary": tender_context,
                "document_analyses": document_analyses,
                "overall_analysis": overall_analysis,
                "analysis_timestamp": asyncio.get_event_loop().time()
            }
        except Exception as e:
            logger.error(f"[analyzer] ‚ùå –û—à–∏–±–∫–∞ –≤ analyze_tender_documents: {e}")
            return None
    
    def _prepare_tender_context(self, tender_info: Dict) -> Dict:
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ–Ω–¥–µ—Ä–µ"""
        try:
            raw_data = tender_info.get('raw_data', {})
            
            return {
                "customer": tender_info.get('customer', '–ù–µ —É–∫–∞–∑–∞–Ω'),
                "subject": tender_info.get('subject', '–ù–µ —É–∫–∞–∑–∞–Ω'),
                "price": tender_info.get('price', '–ù–µ —É–∫–∞–∑–∞–Ω–∞'),
                "publication_date": tender_info.get('publication_date', '–ù–µ —É–∫–∞–∑–∞–Ω–∞'),
                "submission_deadline": tender_info.get('submission_deadline', '–ù–µ —É–∫–∞–∑–∞–Ω–∞'),
                "status": tender_info.get('status', '–ù–µ —É–∫–∞–∑–∞–Ω'),
                "document_count": tender_info.get('document_count', 0),
                "raw_data_summary": self._extract_key_info(raw_data)
            }
        except Exception as e:
            logger.error(f"[analyzer] ‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {e}")
            return {"error": "–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö —Ç–µ–Ω–¥–µ—Ä–∞"}
    
    def _extract_key_info(self, raw_data: Dict) -> Dict:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            return {
                "procurement_type": raw_data.get('–¢–∏–ø–ó–∞–∫—É–ø–∫–∏', '–ù–µ —É–∫–∞–∑–∞–Ω'),
                "procurement_method": raw_data.get('–°–ø–æ—Å–æ–±–ó–∞–∫—É–ø–∫–∏', '–ù–µ —É–∫–∞–∑–∞–Ω'),
                "delivery_place": raw_data.get('–ú–µ—Å—Ç–æ–ü–æ—Å—Ç–∞–≤–∫–∏', '–ù–µ —É–∫–∞–∑–∞–Ω–æ'),
                "delivery_terms": raw_data.get('–°—Ä–æ–∫–ü–æ—Å—Ç–∞–≤–∫–∏', '–ù–µ —É–∫–∞–∑–∞–Ω'),
                "requirements": raw_data.get('–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è', {}),
                "conditions": raw_data.get('–£—Å–ª–æ–≤–∏—è', {})
            }
        except Exception as e:
            logger.error(f"[analyzer] ‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–ª—é—á–µ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: {e}")
            return {}
    
    async def _analyze_single_document(self, file_info: Dict, tender_context: Dict) -> Optional[Dict]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ–¥–∏–Ω –¥–æ–∫—É–º–µ–Ω—Ç"""
        try:
            file_path = Path(file_info['path'])
            if not file_path.exists():
                logger.warning(f"[analyzer] ‚ö†Ô∏è –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
                return None
            
            # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
            content = await self._read_file_content(file_path)
            if not content:
                logger.warning(f"[analyzer] ‚ö†Ô∏è –ü—É—Å—Ç–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞: {file_path}")
                return None
            
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            prompt = self._create_analysis_prompt(content, tender_context, file_info['original_name'])
            logger.info(f"[analyzer] –ü—Ä–æ–º–ø—Ç –¥–ª—è GPT (–ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤): {prompt[:500]}")
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ OpenAI
            analysis = await self._call_openai_api(prompt)
            logger.info(f"[analyzer] –û—Ç–≤–µ—Ç GPT (–ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤): {str(analysis)[:500]}")
            
            return {
                "file_name": file_info['original_name'],
                "file_size": file_info['size'],
                "analysis": analysis,
                "content_preview": content[:500] + "..." if len(content) > 500 else content
            }
            
        except Exception as e:
            logger.error(f"[analyzer] ‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
            return None
    
    async def _read_file_content(self, file_path: Path) -> Optional[str]:
        """–ß–∏—Ç–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç, docx, doc, pdf, xls, xlsx, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∞—Ä—Ö–∏–≤—ã"""
        import subprocess
        ext = file_path.suffix.lower()
        try:
            if ext == '.txt':
                import aiofiles
                async with aiofiles.open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    return await f.read()
            elif ext == '.docx':
                import docx2txt
                return docx2txt.process(str(file_path))
            elif ext == '.doc':
                # –¢—Ä–µ–±—É–µ—Ç—Å—è —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–π antiword
                result = subprocess.run(['antiword', str(file_path)], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
                return result.stdout.decode('utf-8', errors='ignore')
            elif ext == '.pdf':
                text = ""
                with open(file_path, 'rb') as file:
                    pdf_reader = PyPDF2.PdfReader(file)
                    for page in pdf_reader.pages:
                        text += page.extract_text() + "\n"
                return text
            elif ext in ['.xls', '.xlsx']:
                import pandas as pd
                df = pd.read_excel(str(file_path), dtype=str, engine='openpyxl' if ext == '.xlsx' else None)
                return df.to_string(index=False)
            elif ext in ['.jpg', '.jpeg', '.png']:
                from PIL import Image
                import pytesseract
                img = Image.open(file_path)
                return pytesseract.image_to_string(img, lang='rus+eng')
            elif ext == '.zip':
                import zipfile, tempfile
                texts = []
                with zipfile.ZipFile(file_path, 'r') as zf:
                    for member in zf.namelist():
                        if not member.endswith('/'):
                            with zf.open(member) as f, tempfile.NamedTemporaryFile(delete=False, suffix=Path(member).suffix) as tmp:
                                tmp.write(f.read())
                                tmp_path = Path(tmp.name)
                            text = await self._read_file_content(tmp_path)
                            if text:
                                texts.append(f'--- {member} ---\n{text}')
                            tmp_path.unlink(missing_ok=True)
                return '\n\n'.join(texts)
            elif ext == '.rar':
                import rarfile, tempfile
                texts = []
                with rarfile.RarFile(str(file_path)) as rf:
                    for member in rf.namelist():
                        if not member.endswith('/'):
                            with rf.open(member) as f, tempfile.NamedTemporaryFile(delete=False, suffix=Path(member).suffix) as tmp:
                                tmp.write(f.read())
                                tmp_path = Path(tmp.name)
                            text = await self._read_file_content(tmp_path)
                            if text:
                                texts.append(f'--- {member} ---\n{text}')
                            tmp_path.unlink(missing_ok=True)
                return '\n\n'.join(texts)
            else:
                return None
        except Exception as e:
            logger.error(f'[analyzer] ‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {file_path}: {e}')
            return None
    
    def _create_analysis_prompt(self, content: str, tender_context: Dict, filename: str) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        return f"""
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–æ–∫—É–º–µ–Ω—Ç —Ç–µ–Ω–¥–µ—Ä–∞ "{filename}" –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑.

–ö–æ–Ω—Ç–µ–∫—Å—Ç —Ç–µ–Ω–¥–µ—Ä–∞:
- –ó–∞–∫–∞–∑—á–∏–∫: {tender_context.get('customer', '–ù–µ —É–∫–∞–∑–∞–Ω')}
- –ü—Ä–µ–¥–º–µ—Ç: {tender_context.get('subject', '–ù–µ —É–∫–∞–∑–∞–Ω')}
- –¶–µ–Ω–∞: {tender_context.get('price', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')}
- –°—Ä–æ–∫ –ø–æ–¥–∞—á–∏: {tender_context.get('submission_deadline', '–ù–µ —É–∫–∞–∑–∞–Ω')}

–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞:
{content[:4000]}  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –¥–ª—è API

–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–æ–∫—É–º–µ–Ω—Ç –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å:

1. **–ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ** (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
2. **–¢–æ–≤–∞—Ä–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏** (—Å–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤/—É—Å–ª—É–≥)
3. **–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —É–ø–∞–∫–æ–≤–∫–µ** (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã)
4. **–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Å–æ—Ä—Ç—É/–∫–∞—á–µ—Å—Ç–≤—É** (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã)
5. **–ö–ª—é—á–µ–≤—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è** (–≤–∞–∂–Ω—ã–µ —É—Å–ª–æ–≤–∏—è —É—á–∞—Å—Ç–∏—è)
6. **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏** (—Å—Ç–æ–∏—Ç –ª–∏ —É—á–∞—Å—Ç–≤–æ–≤–∞—Ç—å, –Ω–∞ —á—Ç–æ –æ–±—Ä–∞—Ç–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ)

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∏ —É–¥–æ–±–Ω—ã–º –¥–ª—è —á—Ç–µ–Ω–∏—è.
"""
    
    async def _call_openai_api(self, prompt: str) -> str:
        try:
            logger.info(f"[analyzer] –û—Ç–ø—Ä–∞–≤–ª—è—é –≤ OpenAI prompt –¥–ª–∏–Ω–æ–π {len(prompt)} —Å–∏–º–≤–æ–ª–æ–≤")
            response = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=1200,
                    temperature=0.2,
                )
            )
            answer = response.choices[0].message.content
            logger.info(f"[analyzer] –û—Ç–≤–µ—Ç OpenAI (–ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤): {answer[:500]}")
            return answer
        except Exception as e:
            logger.error(f"[analyzer] ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ OpenAI: {e}")
            return None
    
    async def _setup_vpn_connection(self):
        """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç VPN —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ OpenAI"""
        try:
            # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏–∫—É –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ VPN
            # –ù–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ WireGuard –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
            logger.info(f"[analyzer] üîí –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è VPN –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å: {VPN_INTERFACE}")
        except Exception as e:
            logger.warning(f"[analyzer] ‚ö†Ô∏è –û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ VPN: {e}")
    
    async def _create_overall_analysis(self, tender_info: Dict, document_analyses: List[Dict]) -> Dict:
        """–°–æ–∑–¥–∞–µ—Ç –æ–±—â–∏–π –∞–Ω–∞–ª–∏–∑ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        if not document_analyses:
            return {"summary": "–ù–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"}
        
        try:
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑—ã –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            combined_analysis = "\n\n".join([
                f"–î–æ–∫—É–º–µ–Ω—Ç: {doc['file_name']}\n{doc['analysis']}"
                for doc in document_analyses
            ])
            
            prompt = f"""
–ù–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Ç–µ–Ω–¥–µ—Ä–∞, —Å–æ–∑–¥–∞–π –æ–±—â–µ–µ —Ä–µ–∑—é–º–µ:

–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–µ–Ω–¥–µ—Ä–µ:
- –ó–∞–∫–∞–∑—á–∏–∫: {tender_info.get('customer', '–ù–µ —É–∫–∞–∑–∞–Ω')}
- –ü—Ä–µ–¥–º–µ—Ç: {tender_info.get('subject', '–ù–µ —É–∫–∞–∑–∞–Ω')}
- –¶–µ–Ω–∞: {tender_info.get('price', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')}

–ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:
{combined_analysis[:3000]}

–ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å:
1. **–û–±—â–µ–µ —Ä–µ–∑—é–º–µ —Ç–µ–Ω–¥–µ—Ä–∞** (3-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
2. **–û—Å–Ω–æ–≤–Ω—ã–µ —Ç–æ–≤–∞—Ä–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏**
3. **–ö–ª—é—á–µ–≤—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∏ —É—Å–ª–æ–≤–∏—è**
4. **–†–∏—Å–∫–∏ –∏ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏**
5. **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ø–æ —É—á–∞—Å—Ç–∏—é** (—É—á–∞—Å—Ç–≤–æ–≤–∞—Ç—å/–Ω–µ —É—á–∞—Å—Ç–≤–æ–≤–∞—Ç—å –∏ –ø–æ—á–µ–º—É)
6. **–û—Ü–µ–Ω–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏** (–ø—Ä–æ—Å—Ç–æ–π/—Å—Ä–µ–¥–Ω–∏–π/—Å–ª–æ–∂–Ω—ã–π)

–ë—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∏ –ø—Ä–∞–∫—Ç–∏—á–Ω—ã–º –≤ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è—Ö.
"""
            
            overall_analysis = await self._call_openai_api(prompt)
            
            return {
                "summary": overall_analysis,
                "document_count": len(document_analyses),
                "analysis_quality": "complete" if document_analyses else "incomplete"
            }
            
        except Exception as e:
            logger.error(f"[analyzer] ‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ–±—â–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return {"summary": f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ–±—â–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}"}
    
    def _create_empty_analysis(self) -> Dict:
        """–°–æ–∑–¥–∞–µ—Ç –ø—É—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        return {
            "tender_summary": {},
            "document_analyses": [],
            "overall_analysis": {
                "summary": "–î–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã",
                "document_count": 0,
                "analysis_quality": "no_documents"
            },
            "analysis_timestamp": asyncio.get_event_loop().time()
        }

# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
analyzer = DocumentAnalyzer(OPENAI_API_KEY)

async def analyze_tender_documents(tender_info: Dict, downloaded_files: List[Dict]) -> Dict:
    """–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º –∫–æ–¥–æ–º"""
    return await analyzer.analyze_tender_documents(tender_info, downloaded_files) 