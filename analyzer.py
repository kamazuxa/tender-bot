import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
print("[analyzer] analyzer.py –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
import asyncio
from typing import Dict, List, Optional
from pathlib import Path
from openai import OpenAI
from config import OPENAI_API_KEY, OPENAI_MODEL, USE_VPN_FOR_OPENAI, VPN_INTERFACE
import mimetypes
try:
    import pytesseract
    from PIL import Image
    OCR_SUPPORT = True
except ImportError:
    OCR_SUPPORT = False
try:
    import PyPDF2
    PDF_SUPPORT = True
except ImportError:
    PDF_SUPPORT = False
import fitz  # PyMuPDF
import docx2txt
import pandas as pd

logger = logging.getLogger(__name__)

class DocumentAnalyzer:
    def __init__(self, api_key: str, model: str = OPENAI_MODEL):
        self.api_key = api_key
        self.model = model
        self.client = OpenAI(api_key=api_key)
    
    async def analyze_tender_documents(self, tender_info: Dict, downloaded_files: List[Dict]) -> str:
        print("[analyzer] analyze_tender_documents (–æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π —Ä–µ–∂–∏–º) –≤—ã–∑–≤–∞–Ω")
        logger.info("[analyzer] analyze_tender_documents (–æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π —Ä–µ–∂–∏–º) –≤—ã–∑–≤–∞–Ω")
        if not downloaded_files:
            logger.info("[analyzer] üìÑ –ù–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return "–î–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã."
        # 1. –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç—ã
        texts = []
        for file_info in downloaded_files:
            file_path = Path(file_info['path'])
            text = await self.extract_text_from_file(file_path)
            logger.info(f"[analyzer] {file_path} ‚Äî –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {len(text) if text else 0}")
            logger.info(f"[analyzer] {file_path} ‚Äî –ø–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤: {text[:200] if text else '–ü–£–°–¢–û'}")
            if not text or len(text.strip()) < 100:
                logger.warning(f"[analyzer] –§–∞–π–ª {file_path} –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω (–º–∞–ª–æ —Ç–µ–∫—Å—Ç–∞)")
                continue
            # –û—á–∏—Å—Ç–∫–∞ –º—É—Å–æ—Ä–∞ (—Ñ—É—Ç–µ—Ä—ã, –¥–∞—Ç—ã, –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –∑–∞–≥–æ–ª–æ–≤–∫–∏)
            text = self.cleanup_text(text)
            texts.append((file_info.get('original_name', str(file_path)), text))
        if not texts:
            logger.info("[analyzer] –ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return "–ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."
        # 2. –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å –º–µ—Ç–∫–∞–º–∏
        doc_texts = [f"==== –î–û–ö–£–ú–ï–ù–¢: {name} ====" + "\n" + t for name, t in texts]
        full_text = "\n\n".join(doc_texts)
        logger.info(f"[analyzer] –ò—Ç–æ–≥–æ–≤—ã–π full_text –¥–ª–∏–Ω–∞: {len(full_text)}")
        logger.info(f"[analyzer] –ò—Ç–æ–≥–æ–≤—ã–π full_text –ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤: {full_text[:500]}")
        # 3. –û–±—Ä–µ–∑–∞–µ–º –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ (–ª–∏–º–∏—Ç 15000 —Ç–æ–∫–µ–Ω–æ–≤ ‚âà 60000 —Å–∏–º–≤–æ–ª–æ–≤)
        max_len = 60000
        if len(full_text) > max_len:
            logger.warning(f"[analyzer] –°—É–º–º–∞—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏–º–∏—Ç, –±—É–¥–µ—Ç —É—Å–µ—á—ë–Ω")
            # –†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ —Å–æ–∫—Ä–∞—â–∞–µ–º –∫–∞–∂–¥—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
            n = len(doc_texts)
            chunk = max_len // n
            doc_texts = [t[:chunk] for t in doc_texts]
            full_text = "\n\n".join(doc_texts)
        # 4. –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç
        prompt = self.make_analysis_prompt(full_text)
        logger.info(f"DEBUG prompt preview: {prompt[:2000]}")
        logger.info(f"[analyzer] –û—Ç–ø—Ä–∞–≤–ª—è—é –≤ OpenAI –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª–∏–Ω–æ–π {len(prompt)} —Å–∏–º–≤–æ–ª–æ–≤")
        # 5. –û–¥–∏–Ω –≤—ã–∑–æ–≤ –∫ OpenAI
        analysis = await self._call_openai_api(prompt)
        if not analysis:
            logger.error("[analyzer] –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –æ—Ç OpenAI")
            return "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∞–Ω–∞–ª–∏–∑ —Ç–µ–Ω–¥–µ—Ä–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
        return analysis
    
    async def extract_text_from_file(self, file_path: Path) -> Optional[str]:
        """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞ (PDF, DOCX, XLSX, ZIP –∏ –¥—Ä.)"""
        ext = file_path.suffix.lower()
        try:
            if ext == '.txt':
                import aiofiles
                async with aiofiles.open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    return await f.read()
            elif ext == '.docx':
                return docx2txt.process(str(file_path))
            elif ext == '.doc':
                import subprocess
                result = subprocess.run(['antiword', str(file_path)], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
                return result.stdout.decode('utf-8', errors='ignore')
            elif ext == '.pdf':
                text = ""
                with fitz.open(str(file_path)) as doc:
                    for page in doc:
                        text += page.get_text()
                return text
            elif ext in ['.xls', '.xlsx']:
                df = pd.read_excel(str(file_path), dtype=str, engine='openpyxl' if ext == '.xlsx' else None)
                return df.to_string(index=False)
            elif ext in ['.jpg', '.jpeg', '.png']:
                from PIL import Image
                import pytesseract
                img = Image.open(file_path)
                return pytesseract.image_to_string(img, lang='rus+eng')
            elif ext == '.zip':
                import zipfile, tempfile
                texts = []
                with zipfile.ZipFile(file_path, 'r') as zf:
                    for member in zf.namelist():
                        if not member.endswith('/'):
                            with zf.open(member) as f, tempfile.NamedTemporaryFile(delete=False, suffix=Path(member).suffix) as tmp:
                                tmp.write(f.read())
                                tmp_path = Path(tmp.name)
                            text = await self.extract_text_from_file(tmp_path)
                            if text:
                                texts.append(f'--- {member} ---\n{text}')
                            tmp_path.unlink(missing_ok=True)
                return '\n\n'.join(texts)
            elif ext == '.rar':
                import rarfile, tempfile
                texts = []
                with rarfile.RarFile(str(file_path)) as rf:
                    for member in rf.namelist():
                        if not member.endswith('/'):
                            with rf.open(member) as f, tempfile.NamedTemporaryFile(delete=False, suffix=Path(member).suffix) as tmp:
                                tmp.write(f.read())
                                tmp_path = Path(tmp.name)
                            text = await self.extract_text_from_file(tmp_path)
                            if text:
                                texts.append(f'--- {member} ---\n{text}')
                            tmp_path.unlink(missing_ok=True)
                return '\n\n'.join(texts)
            else:
                return None
        except Exception as e:
            logger.error(f'[extract_text_from_file] ‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {file_path}: {e}')
            return None
    
    def cleanup_text(self, text: str) -> str:
        """–£–¥–∞–ª—è–µ—Ç –º—É—Å–æ—Ä: —Ñ—É—Ç–µ—Ä—ã, –¥–∞—Ç—ã, –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ —Ç.–ø."""
        import re
        # –£–¥–∞–ª—è–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –∑–∞–≥–æ–ª–æ–≤–∫–∏
        lines = text.splitlines()
        seen = set()
        cleaned = []
        for line in lines:
            l = line.strip()
            if l and l not in seen:
                cleaned.append(l)
                seen.add(l)
        text = "\n".join(cleaned)
        # –£–¥–∞–ª—è–µ–º –¥–∞—Ç—ã (–ø—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞)
        text = re.sub(r'\d{2,4}[./-]\d{2}[./-]\d{2,4}', '', text)
        # –£–¥–∞–ª—è–µ–º —Ñ—É—Ç–µ—Ä—ã (–ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º)
        text = re.sub(r'—Å—Ç—Ä–∞–Ω–∏—Ü–∞ \d+ –∏–∑ \d+', '', text, flags=re.I)
        return text
    
    def make_analysis_prompt(self, full_text: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        return f"""
–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –≥–æ—Å–∑–∞–∫—É–ø–∫–∞–º –∏ –∞–Ω–∞–ª–∏–∑—É —Ç–µ–Ω–¥–µ—Ä–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏.

–í–æ—Ç –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∑–∞–∫—É–ø–∫–∏ (–¢–ó, –∫–æ–Ω—Ç—Ä–∞–∫—Ç, –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –∏ –¥—Ä.), —Ä–∞–∑–¥–µ–ª—ë–Ω–Ω—ã—Ö –º–∞—Ä–∫–µ—Ä–∞–º–∏ ==== –î–û–ö–£–ú–ï–ù–¢ ====. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏—Ö –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ –∏ –≤—ã–ø–æ–ª–Ω–∏ —Å–ª–µ–¥—É—é—â–∏–µ –∑–∞–¥–∞—á–∏:

1. –î–∞–π –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∑–∞–∫—É–ø–∫–∏: –∫–∞–∫–∏–µ —Ç–æ–≤–∞—Ä—ã/—É—Å–ª—É–≥–∏ —Ç—Ä–µ–±—É—é—Ç—Å—è, –æ–±—ä—ë–º—ã, –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ (–ì–û–°–¢, —Ñ–∞—Å–æ–≤–∫–∞, —Å–æ—Ä—Ç, –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è, —Å—Ä–æ–∫–∏ –∏ —Ç.–ø.).
2. –û–ø—Ä–µ–¥–µ–ª–∏ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —Ä–∏—Å–∫–∏ –∏ –ø–æ–¥–≤–æ–¥–Ω—ã–µ –∫–∞–º–Ω–∏ –¥–ª—è —É—á–∞—Å—Ç–Ω–∏–∫–∞ –∑–∞–∫—É–ø–∫–∏ (–Ω–µ—è—Å–Ω–æ—Å—Ç–∏ –≤ –¢–ó, —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —É–ø–∞–∫–æ–≤–∫–µ, –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–æ –ø–æ—Å—Ç–∞–≤–∫–µ, –ª–æ–≥–∏—Å—Ç–∏–∫–µ, —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏ —Ç.–¥.).
3. –î–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: —Å—Ç–æ–∏—Ç –ª–∏ —É—á–∞—Å—Ç–≤–æ–≤–∞—Ç—å –≤ –∑–∞–∫—É–ø–∫–µ —Å —É—á—ë—Ç–æ–º —ç—Ç–∏—Ö —Ä–∏—Å–∫–æ–≤? –ü–æ—á–µ–º—É –¥–∞ –∏–ª–∏ –ø–æ—á–µ–º—É –Ω–µ—Ç?
4. –°—Ñ–æ—Ä–º–∏—Ä—É–π –ø–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã –≤ –Ø–Ω–¥–µ–∫—Å–µ –¥–ª—è –∫–∞–∂–¥–æ–π —Ç–æ–≤–∞—Ä–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏, —á—Ç–æ–±—ã –Ω–∞–π—Ç–∏ –ø–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤ –≤ –†–æ—Å—Å–∏–∏. –ó–∞–ø—Ä–æ—Å—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–º–∏ –¥–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, —Ü–µ–Ω –∏ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤. –í–∫–ª—é—á–∞–π: ‚Äì –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ (–∫—Ä–∞—Ç–∫–æ), ‚Äì —Å–æ—Ä—Ç/–º–∞—Ä–∫—É/–º–æ–¥–µ–ª—å, ‚Äì –ì–û–°–¢/–¢–£, ‚Äì —Ñ–∞—Å–æ–≤–∫—É/—É–ø–∞–∫–æ–≤–∫—É, ‚Äì –æ–±—ä—ë–º (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ), ‚Äì –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: –∫—É–ø–∏—Ç—å, –æ–ø—Ç–æ–º, —Ü–µ–Ω–∞, –ø–æ—Å—Ç–∞–≤—â–∏–∫.

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
–ê–Ω–∞–ª–∏–∑: <...>
–ü–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã:
1. <–ø–æ–∑–∏—Ü–∏—è>: <–ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å>
2. ...
"""
    
    async def _call_openai_api(self, prompt: str) -> str:
        print("[analyzer] _call_openai_api –≤—ã–∑–≤–∞–Ω")
        logger.info("[analyzer] _call_openai_api –≤—ã–∑–≤–∞–Ω")
        try:
            logger.info(f"[analyzer] –û—Ç–ø—Ä–∞–≤–ª—è—é –≤ OpenAI prompt –¥–ª–∏–Ω–æ–π {len(prompt)} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"[analyzer] –û—Ç–ø—Ä–∞–≤–ª—è—é –≤ OpenAI prompt –¥–ª–∏–Ω–æ–π {len(prompt)} —Å–∏–º–≤–æ–ª–æ–≤")
            response = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=1200,
                    temperature=0.2,
                )
            )
            answer = response.choices[0].message.content
            logger.info(f"[analyzer] –û—Ç–≤–µ—Ç OpenAI (–ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤): {answer[:500]}")
            print(f"[analyzer] –û—Ç–≤–µ—Ç OpenAI (–ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤): {answer[:500]}")
            return answer
        except Exception as e:
            logger.error(f"[analyzer] ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ OpenAI: {e}")
            print(f"[analyzer] ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ OpenAI: {e}")
            return None
    
    async def _setup_vpn_connection(self):
        """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç VPN —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ OpenAI"""
        try:
            # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏–∫—É –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ VPN
            # –ù–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ WireGuard –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
            logger.info(f"[analyzer] üîí –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è VPN –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å: {VPN_INTERFACE}")
        except Exception as e:
            logger.warning(f"[analyzer] ‚ö†Ô∏è –û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ VPN: {e}")
    
    async def _create_overall_analysis(self, tender_info: Dict, document_analyses: List[Dict]) -> Dict:
        """–°–æ–∑–¥–∞–µ—Ç –æ–±—â–∏–π –∞–Ω–∞–ª–∏–∑ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        if not document_analyses:
            return {"summary": "–ù–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"}
        
        try:
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑—ã –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            combined_analysis = "\n\n".join([
                f"–î–æ–∫—É–º–µ–Ω—Ç: {doc['file_name']}\n{doc['analysis']}"
                for doc in document_analyses
            ])
            
            prompt = f"""
–ù–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Ç–µ–Ω–¥–µ—Ä–∞, —Å–æ–∑–¥–∞–π –æ–±—â–µ–µ —Ä–µ–∑—é–º–µ:

–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–µ–Ω–¥–µ—Ä–µ:
- –ó–∞–∫–∞–∑—á–∏–∫: {tender_info.get('customer', '–ù–µ —É–∫–∞–∑–∞–Ω')}
- –ü—Ä–µ–¥–º–µ—Ç: {tender_info.get('subject', '–ù–µ —É–∫–∞–∑–∞–Ω')}
- –¶–µ–Ω–∞: {tender_info.get('price', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')}

–ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:
{combined_analysis[:3000]}

–ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å:
1. **–û–±—â–µ–µ —Ä–µ–∑—é–º–µ —Ç–µ–Ω–¥–µ—Ä–∞** (3-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
2. **–û—Å–Ω–æ–≤–Ω—ã–µ —Ç–æ–≤–∞—Ä–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏**
3. **–ö–ª—é—á–µ–≤—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∏ —É—Å–ª–æ–≤–∏—è**
4. **–†–∏—Å–∫–∏ –∏ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏**
5. **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ø–æ —É—á–∞—Å—Ç–∏—é** (—É—á–∞—Å—Ç–≤–æ–≤–∞—Ç—å/–Ω–µ —É—á–∞—Å—Ç–≤–æ–≤–∞—Ç—å –∏ –ø–æ—á–µ–º—É)
6. **–û—Ü–µ–Ω–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏** (–ø—Ä–æ—Å—Ç–æ–π/—Å—Ä–µ–¥–Ω–∏–π/—Å–ª–æ–∂–Ω—ã–π)

–ë—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∏ –ø—Ä–∞–∫—Ç–∏—á–Ω—ã–º –≤ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è—Ö.
"""
            
            overall_analysis = await self._call_openai_api(prompt)
            
            return {
                "summary": overall_analysis,
                "document_count": len(document_analyses),
                "analysis_quality": "complete" if document_analyses else "incomplete"
            }
            
        except Exception as e:
            logger.error(f"[analyzer] ‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ–±—â–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return {"summary": f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ–±—â–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}"}
    
    def _create_empty_analysis(self) -> Dict:
        """–°–æ–∑–¥–∞–µ—Ç –ø—É—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        return {
            "tender_summary": {},
            "document_analyses": [],
            "overall_analysis": {
                "summary": "–î–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã",
                "document_count": 0,
                "analysis_quality": "no_documents"
            },
            "analysis_timestamp": asyncio.get_event_loop().time()
        }

# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
analyzer = DocumentAnalyzer(OPENAI_API_KEY)

async def analyze_tender_documents(tender_info: Dict, downloaded_files: List[Dict]) -> Dict:
    """–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º –∫–æ–¥–æ–º"""
    return await analyzer.analyze_tender_documents(tender_info, downloaded_files) 